<!DOCTYPE html>
<html>

<head>
    <title>Automated Prompting Systems</title>
    <link rel="stylesheet" type="text/css" href="../light-style.css">
</head>

<body>
    <h1>An Introduction to Automated Prompting and Deep Intelligent Systems</h1>
</body>

<p><em>
        "In the era of ChatGPT and GPT-4, proper usage of AIs influences their capabilities
        even more than their weights."
</p></em>

<p>By Trent Fellbootman</p>

<h2>Overview</h2>

<div>
    <p>
        This blog introduces automated prompting, a new paradigm of utilizing AIs. Basically,
        this blog discusses how to use modern AIs to do virtually anything, efficiently and reliably.
    </p>

    <p>The blog is divided into 4 parts:</p>

    <ul>
        <li><strong>Overview</strong> (current section)</li>
        <li><strong>Introduction</strong>: Introduces the basics of deep learning and prompting.
            You are <strong>recommended to skip this section</strong> if you already know what deep learning is.</li>
        <li><strong>Automated Prompting and Deep Intelligent Systems</strong>:
            Introduces the concepts and explains what these terms mean.</li>
        <li><strong>Designing Deep Intelligent Systems</strong>: Explains general guidelines for building
            capable and reliable AI systems with examples.</li>
    </ul>

</div>

<h2>Introduction</h2>

<div>

    <p>
        Until not very long ago, deep learning development has been a 4-step process:
        design a model, train the model, evaluate the model, and deploy the model.
        Researchers and engineers have made tremendous efforts in improving the architectures
        of deep learning models and finding efficient ways to obtain high-performance weights
        with minimum computation and data. With recent advancements in large language models (LLMs)
        such as ChatGPT, however, another aspect in AI is becoming increasingly important:
        prompting.
    </p>

    <p>
        The very idea of prompting has been around for a while, and there is even a term for
        the process of designing good prompts: "prompt engineering". However, there have been no serious,
        systematic research into the topic until this blog, and the "state of the art" of prompting have remained
        quite primitive: you design a good prompt, feed it to a model, and you are done.
    </p>

    <p>
        This is going to change. In this blog, I will introduce the concepts of automated prompting and
        deep Intelligent systems, as well the general guidelines for designing such systems. These discussions
        transforms prompting from an art to a science, and open ups a way to boost the capabilities of AI
        in a dimension that has never been explored before.
    </p>
</div>

<h2>Automated Prompting and Deep Intelligent Systems</h2>

<div>
    Simply put, <strong>automated prompting</strong> is letting AIs to talk to other AIs, and a <strong>deep intelligent
        system</strong> is a system formed by a group of AIs who (yep, "who", not "which") use automated prompting to
    communicate and collaborate
    to achieve a certain goal, possibly using non-AI resources and tools as well, including Python interpreters,
    databases, web browsers,
    humans, etc.

    <h3>Example: Automated Prompting</h3>

    <p>
        If you have two iPhones, you can open up Siri on both of them and let the two Siris talk to each other.
        This is a simple example of automated prompting, although it not very useful. In this example, the output
        of one Siri (which is <strong><em>"automatically"</em></strong> generated) is used as input
        (the <strong><em>"prompt"</em></strong>) to the other Siri. For this, letting two Siris talk to each
        other is considered <strong><em>"automated prompting"</em></strong>.
    </p>

    <h3>Example: Deep Intelligent System</h3>

    <p>
        Suppose you need to create a video about some famous animals in Australia. You can achieve this goal with the
        following plan:
    </p>

    <ol>
        <li>
            Use New Bing to find some of the most famous animals in Australia.
        </li>
        <li>
            For each of the animals, use Gen-1 (a model that generates video from text) to generate
            a video about the animal, use ChatGPT to generate a script introducing the animal, and use
            a voice synthesis model (a model that generates speech from text) to generate a speech for the script.
        </li>
        <li>
            Merge the videos, speeches together and make subtitles with scripts.
        </li>
    </ol>

    <p>
        This is a basic deep intelligent systems, consisting of multiple intelligent agents such as New Bing, Gen-1 and
        voice synthesis models. The intelligent agents talk to each other: New Bing talks with Gen-1, telling it what
        prompt to use to generate the video, and with ChatGPT, telling it what the script it generates should be about.
    </p>

    <p>
        However, such an intelligent system is not fully autonomous, as you, the human, still need to act as the planner
        who creates the high-level plan, as well as the mediator, helping the intelligent agents to talk with each other
        (e.g., by copying what New Bing returns and pasting it to Gen-1 and ChatGPT). In the next sections, I will show
        you how to make this process fully autonomous: that is, tell the system that you need to "create a video about
        some famous animals in Australia", and let the AIs handle the rest.
    </p>
</div>

<h2>Designing Deep Intelligent Systems</h2>

<div>

    <h3>Error Correction</h3>
    <p>
        One fundamental difference between AIs and traditional, non-intelligent computer programs is that <strong>AIs
            make mistakes</strong>, and they are better viewed as <strong>human-like assistants with both the merits and
            the flaws of humanity</strong>, rather than cold machines with no emotions, machines that work forever
        without ever making a mistake.
    </p>

    <p>
        This fundamental difference leads to such a fact that error correction, something never considered when writing
        a traditional computer program, suddenly becomes an noticeable issue that must be properly addressed when AIs
        come in to play. In traditional computer programs, we know exactly and deterministically what the program would
        do, and as long as the input to the program is valid, the output will always be valid, as long as there is no
        bug in the program. However, AIs may produce invalid outputs even if the input is perfectly valid.</p>

    <p>
        For example, if you ask the AI, "What is the product of 17 and 19?" (the correct answer is 323), the AI might
        fail to compute the right answer, just like any human might do. Humans are not good at numerical computing, and
        neither is a large language model.
    </p>

    <p>
        Another typical example is when you want the AI to give output in a specific format. For example, if you tell
        ChatGPT, "How do I make a folder in a linux terminal? Output the command ONLY and NOTHING ELSE.", ChatGPT may
        still reply "The command is 'mkdir'." Such behavior is completely understandable, as ChatGPT is trained to
        mimick a human assistant, and as a result, it is not comfortable with "speaking in a specific format", just like
        us.
    </p>

    <p>
        The first example has a simple solution: instead of asking the AI to do the computation itself, ask it to write
        a program that does the computation (Just like what a human would do, right?).
    </p>

    <p>
        The solution to the second example may not be as obvious. However, the ability to generate output both
        intelligently and in a specific format is crucial in constructing large, complex and effective intelligent
        systems (as we will see in the next few sections). So how do we make an AI follow the formats we specify? The
        answer is "<strong>AIs correct AIs</strong>".
    </p>

    <h4>AIs Correct AIs</h4>

    <p>
        Before we jump to the solution, let's think about the problem. The problem is that AIs make mistakes, just like
        humans do, and we want them not to make mistakes. So a natural idea is, use whatever makes humans more reliable
        to make the AIs reliable.
    </p>

    <p>
        What makes humans reliable? Supervision from other humans! Anyone can make a mistake; but when there is another
        person checking his/her work, the probability of a mistake becomes much lower. For example, it is very easy for
        someone to make a mistake in a calculation, but when there is another person doing the same calculation, and the
        results from both persons are compared, it is much harder for the result to be wrong, because in that case, the
        results from the two people are not only wrong, but also the same.
    </p>

    <p>
        The same idea applies to AIs as well. Generally, there are two ways to correct potential errors in AIs' outputs:

    <ul>
        <li>
            <strong>Cross-check</strong>: Instantiate multiple AIs, let them do the same task, and compare the results.
            Reject the results if they are inconsistent; make the AIs redo their jobs until results from all AIs are the
            same. This method only applies to deterministic tasks, i.e., tasks where outputs should always be the same
            with same inputs. Examples of this type of tasks include numeric calculations, etc.
        </li>

        <li>
            <strong>Supervision</strong>: When one "worker" AI finishes his/her/... work, let another "supervisor" AI
            check the result. For example, the supervisor AI may be asked "Is the result in correct format? REPLY 'YES'
            or 'NO' ONLY." (in this case, although the format that the "worker" AI needs to follow might be complex, the
            format that the "supervisor" AI must follow is very simple, and the "supervisor" AI is usually able to
            follow the format. Also, the "supervisor" AI can be asked to regenerate the output until it follows the
            format.) Make the "worker" AI redo the work until the "supervisor" AI says that the result is
            valid.
        </li>
    </ul>
    </p>


</div>

<style>
    body {
        max-width: 750px;
        margin: auto;
    }
</style>

</html>