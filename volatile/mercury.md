# Mercury: 一个跨平台的深度神经网络标准

## 目标

- 大幅降低AI软件开发难度，从“懂深度学习才能开发AI软件”到“会编程就行”
- 为市面上的所有深度学习模型提供一个通用标准，开发者无需了解各个模型的实现细节，只要查阅标准就可以。
- 增强AI软件的通用性、标准性和可维护性，使得软件不依赖于具体的某一个模型，在任意终端设备上只要有兼容的模型或服务就可运行。

## 思路

- 核心想法：依赖于抽象模型而非具体模型。抽象模型例如“一个懂编程的LLM”，具体模型比如“GPT-3.5-Turbo”。
开发者开发软件时依赖抽象模型而非具体模型，软件运行时在终端设备上搜索满足软件要求的模型，
通过某种偏好动态选择具体使用哪一个模型。
例如，AI编程插件要求“懂编程的LLM”，在某手机平台上可能搜索到ChatGPT, GPT-3, GPT-4三种云服务, 最终根据最低价格选择ChatGPT。
- （已完成）通过XML指明每一个模型的各项指标，既有硬指标，如采用什么样的输入输出格式，也有软指标，即模型会不会做数学题、会不会编程等。这个XML叫做manifest。
- （已完成）通过XML指明过滤器。过滤器叫做filter，指明开发者对模型的要求，如输入输出均为字符串并且会编程。
- （已完成）软件在编译时只包含filter，不绑定具体模型。运行时在终端设备上读取所有模型的manifest，一一比对filter，找出满足要求的所有模型。
- （未开始）推出model hub，在云端录入世界各地开发者和学者开发的深度学习模型。推出模型管理工具，用户可以通过这个工具一键下载安装hub上的模型。
目前考虑和Hugging Face合作。

## 当前进度

- 标准框架已经确定，标准已经基本能用，有pip包，有详尽的文档（英文），有项目主页，提供用100行代码实现会画画的聊天机器人的“getting started tutorial”。
- 仍需完善标准。
- 需为更多模型编写中间层，使其能通过Mercury调用。目前思路是设计AI自动为Hugging Face上所有模型生成中间层。

## 链接

- [项目主页](https://trent-fellbootman.github.io/mercury.io/)
- [GitHub](https://github.com/Trent-Fellbootman/mercury)
- [文档](https://mercurynn.readthedocs.io/en/latest/)
- [Test PyPI](https://test.pypi.org/project/mercury-nn/)
